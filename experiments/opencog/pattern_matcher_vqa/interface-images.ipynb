{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import network_runner\n",
    "from splitnet.splitmultidnnmodel import SplitMultidnnRunner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from util import initialize_atomspace_by_facts\n",
    "scheme_directories = [\"~/projects/opencog/examples/pln/conjunction/\",\n",
    "                      \"~/projects/atomspace/examples/rule-engine/rules/\",\n",
    "                      \"~/projects/opencog/opencog/pln/rules/\"]\n",
    "\n",
    "atomspace = initialize_atomspace_by_facts(\"/mnt/fileserver/shared/models/vqa_split_multidnn/vqa_dataset/val_tv_atomspace.scm\",\n",
    "                                          \"conjunction-rule-base-config.scm\",\n",
    "                                          [os.path.expanduser(x) for x in scheme_directories])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup pipeline\n",
    "from pattern_matcher_vqa import PatternMatcherVqaPipeline, runNeuralNetwork\n",
    "\n",
    "from gui_helpers import build_image_feature_extractor, build_question_to_query_converter, MainWindow\n",
    "\n",
    "question2atomeseLibraryPath = ('../question2atomese/target/question2atomese-1.0-SNAPSHOT.jar')\n",
    "atomspace_path = '/mnt/fileserver/shared/models/vqa_split_multidnn/vqa_dataset/atomspace_val.scm'\n",
    "prototxt = '/mnt/fileserver/shared/vital/image-features/test.prototxt'\n",
    "caffemodel = '/mnt/fileserver/shared/vital/image-features/resnet101_faster_rcnn_final_iter_320000_for_36_bboxes.caffemodel'\n",
    "\n",
    "\n",
    "\n",
    "extractor = build_image_feature_extractor(prototxt, caffemodel)\n",
    "\n",
    "question_converter = build_question_to_query_converter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = '/mnt/fileserver/shared/models/vqa_split_multidnn/visual_genome/'\n",
    "network_runner.runner = SplitMultidnnRunner(models)\n",
    "vqa = PatternMatcherVqaPipeline(extractor, question_converter, atomspace, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "images_path = os.path.expanduser('~/projects/semantic-vision-1/experiments/pattern_matcher_vqa/images')\n",
    "\n",
    "images = [os.path.join(images_path, x) for x in os.listdir(images_path)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "window = MainWindow(images, vqa)\n",
    "window.display()\n",
    "window.use_pattern_matcher = False"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
